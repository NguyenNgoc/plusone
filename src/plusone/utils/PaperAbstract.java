package plusone.utils;

import java.util.Arrays;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Random;
import java.util.Set;

import plusone.Main;
import plusone.utils.TrainingPaper;
import plusone.utils.PredictionPaper;

public class PaperAbstract implements TrainingPaper, PredictionPaper {

    public final Integer index;
    public final Integer[] inReferences;
    public final Integer[] outReferences;

    private Map<Integer, Integer> trainingTf;
    private Map<Integer, Integer> testingTf;
    private Map<Integer, Integer> tf;
    public double norm;
    
  /*  protected static Map<Integer, Integer> makeTf(Integer[] abstractWords) {
	Map<Integer, Integer> tf = new HashMap<Integer, Integer>();
	for (Integer word : abstractWords) {
	    if (!tf.containsKey(word))
	    	tf.put(word, 1);
	    else
	    	tf.put(word, tf.get(word) + 1);
	}
	return tf;
    }*/

    public PaperAbstract(int index, Integer[] inReferences, 
			 Integer[] outReferences, 
			 Integer[] abstractWords) {
    	this.index = index;
    	this.inReferences = inReferences;
    	this.outReferences = outReferences;
    	this.tf = new HashMap<Integer, Integer>();
    	for (Integer word : abstractWords) {
    	    if (!tf.containsKey(word))
    	    	tf.put(word, 1);
    	    else
    	    	tf.put(word, tf.get(word) + 1);
    	}
    }

/*    public PaperAbstract(int index, Integer[] inReferences,
			 Integer[] outReferences, Map<Integer, Integer> tf) {
	this.index = index;
	this.inReferences = inReferences;
	this.outReferences = outReferences;
	this.tf = tf;
    }*/

    /**
     * Generates tf depending on training or testing.  This function
     * must be called before we can use this paper in clustering
     * methods.
     */
    public void generateTf(double testWordpercent, Term[] terms, 
			   boolean test){
	Random randGen = Main.getRandomGenerator();
	trainingTf = new HashMap<Integer, Integer>();
	testingTf = test ? new HashMap<Integer, Integer>() : null;
	norm = 0;

	for (Integer word : tf.keySet()) {
	    if (terms != null) terms[word].addDoc(this, test);
	    int freq= tf.get(word);
	    if (test && randGen.nextDouble() < testWordpercent) {
		testingTf.put(word, freq);
	    } else {
		trainingTf.put(word, freq);
		norm+=freq*freq;
		if (!test && terms != null)
		    terms[word].totalCount += tf.get(word);
	    }
	}

    	norm = Math.sqrt(norm);
    }

    public Integer getTrainingTf(Integer word) {
	return trainingTf == null ? 0 : 
	    (trainingTf.containsKey(word) ? trainingTf.get(word):0);
    }

    public Set<Integer> getTrainingWords() {
	return trainingTf.keySet();
    }

    public Integer getTestingTf(Integer word) {
	return testingTf == null ? 0 : 
	    (testingTf.containsKey(word)? testingTf.get(word)ï¼š0);
    }

    public Set<Integer> getTestingWords() {
	return testingTf.keySet();
    }

    public double getNorm() { return norm; }

    public boolean isTest() { return testingTf != null; }
    
    public double similarity(PaperAbstract a){
    	double sim = 0.0;

	for (Map.Entry<Integer, Integer> entry : trainingTf.entrySet()) {
	    int wordId = entry.getKey();
	    int count = entry.getValue();
		sim += count * a.getTrainingTf(wordId);
    	}
    	return sim/(a.getNorm() * norm);
    }

    public boolean equals(Object obj) {
	return obj instanceof PaperAbstract &&
	    this.index == ((PaperAbstract)obj).index;
    }
}
